{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Import the necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import imutils\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.spatial import distance as dist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Define Utiliy Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_people(frame, net, ln, personIdx):\n",
    "    # grab the dimensions of the frame\n",
    "    (H, W) = frame.shape[:2]\n",
    "    \n",
    "    # initialize the list to store box results, confidence, coordinates, centroid\n",
    "    results = []\n",
    "    boxes = []\n",
    "    centroids = []\n",
    "    confidences = []\n",
    "    \n",
    "    # construct a blob from the input frame and then perform a forward pass to the yolo detector\n",
    "    blob = cv2.dnn.blobFromImage(frame, 1 / 255.0, (416, 416), swapRB=True, crop=False)\n",
    "    net.setInput(blob)\n",
    "    l_output = net.forward(ln)\n",
    "\n",
    "    # loop over each of the layer outputs\n",
    "    for output in l_output:\n",
    "        # loop over each of the detections\n",
    "        for detection in output:\n",
    "            # extract the class ID and confidence\n",
    "            scores = detection[5:]\n",
    "            classID = np.argmax(scores)\n",
    "            confidence = scores[classID]\n",
    "\n",
    "            # filter the person and weak classification\n",
    "            if classID == personIdx and confidence > MIN_CONF:\n",
    "                # scale the bounding box coordinates back relative to the size of the image\n",
    "                box = detection[0:4] * np.array([W, H, W, H])\n",
    "                (centerX, centerY, width, height) = box.astype(\"int\")\n",
    "                x = int(centerX - (width / 2))\n",
    "                y = int(centerY - (height / 2))\n",
    "                # update our list of bounding box coordinates, centroids, and confidences\n",
    "                boxes.append([x, y, int(width), int(height)])\n",
    "                centroids.append((centerX, centerY))\n",
    "                confidences.append(float(confidence))\n",
    "\n",
    "    # apply non-maxima suppression to suppress weak, overlapping\n",
    "    idxs = cv2.dnn.NMSBoxes(boxes, confidences, MIN_CONF, NMS_THRESH)\n",
    "\n",
    "    # ensure at least one detection exists\n",
    "    if len(idxs) > 0:\n",
    "        # loop over the indexes we are keeping\n",
    "        for i in idxs.flatten():\n",
    "            (x, y) = (boxes[i][0], boxes[i][1])\n",
    "            (w, h) = (boxes[i][2], boxes[i][3])\n",
    "            r = (confidences[i], (x, y, x + w, y + h), centroids[i])\n",
    "            results.append(r)\n",
    "\n",
    "    # return the list of results\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_min_dist(input_video, num_iter, net, ln, personIdx):\n",
    "    #Check if camera opened successfully\n",
    "    cap = cv2.VideoCapture(input_video)\n",
    "    avgh_list = []\n",
    "    # Read until video is completed\n",
    "    counter = 1\n",
    "    while(cap.isOpened()):\n",
    "        # Capture frame-by-frame\n",
    "        ret, frame = cap.read()\n",
    "        if ret == True:\n",
    "            frame = imutils.resize(frame, width=700)\n",
    "            results = detect_people(frame, net, ln, personIdx)\n",
    "            # Atleast one person should be detected\n",
    "            if len(results) > 0:\n",
    "                # Get the average height of the person in the frame\n",
    "                avgh = np.array([i[3] - i[1] for i in np.array(results)[:,1]]).mean()\n",
    "                avgh_list.append(avgh)\n",
    "                # update the counter\n",
    "                counter = counter + 1\n",
    "            # Break the loop after 50 iterations:\n",
    "            if counter == (num_iter + 1):\n",
    "                break\n",
    "        else: \n",
    "            break\n",
    "    # When everything done, release the video capture object\n",
    "    cap.release()\n",
    "    # Closes all the frames\n",
    "    cv2.destroyAllWindows()\n",
    "    # Get average height in pixels\n",
    "    min_dist = np.array(avgh_list).mean()\n",
    "    return min_dist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model path directory\n",
    "MODEL_PATH = \"model\"\n",
    "\n",
    "# Flag indicating if NVIDIA CUDA GPU should be used\n",
    "USE_GPU = True\n",
    "\n",
    "# Minimum probability to filter out weak detections\n",
    "MIN_CONF = 0.3\n",
    "\n",
    "# threshold when applying non-maxima suppression\n",
    "NMS_THRESH = 0.3\n",
    "\n",
    "# Wether to display the video\n",
    "display = 1\n",
    "\n",
    "# Input Video\n",
    "input_video = \"test_videos/pedestrians.mp4\"\n",
    "\n",
    "# Ouput Video\n",
    "output_file = \"output.avi\"\n",
    "\n",
    "writer = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Loading the YOLO classifier \n",
    "\n",
    "Download the Weight, config, Coco names files from the respective link in the \"model\" directory:\n",
    "\n",
    "- yolo.weigths = \"https://drive.google.com/uc?export=download&id=17Tolx6EAKO4tVO505Dbrr_CMTfBwXaGT\"\n",
    "- yolov3.cfg = \"https://drive.google.com/uc?export=download&id=1l4N7tSaQi5n40eHKC_B2mNZL8vUPUqNo\"\n",
    "- coco.names = \"https://drive.google.com/uc?export=download&id=1rqGCUn4D6yNb9be7lTgpFImnP7z6yl5f\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Settting backend and target to CUDA...\n"
     ]
    }
   ],
   "source": [
    "# load the COCO class labels our YOLO model was trained on\n",
    "labelsPath = os.path.sep.join([MODEL_PATH, \"coco.names\"])\n",
    "LABELS = open(labelsPath).read().strip().split(\"\\n\")\n",
    "\n",
    "# derive the paths to the YOLO weights and model configuration\n",
    "weightsPath = os.path.sep.join([MODEL_PATH, \"yolov3.weights\"])\n",
    "configPath = os.path.sep.join([MODEL_PATH, \"yolov3.cfg\"])\n",
    "\n",
    "# Load the serialized pretrained model\n",
    "net = cv2.dnn.readNetFromDarknet(configPath, weightsPath)\n",
    "# check if we are going to use GPU\n",
    "if USE_GPU:\n",
    "    # set CUDA as the preferable backend and target\n",
    "    print(\"Settting backend and target to CUDA...\")\n",
    "    net.setPreferableBackend(cv2.dnn.DNN_BACKEND_CUDA)\n",
    "    net.setPreferableTarget(cv2.dnn.DNN_TARGET_CUDA)\n",
    "    \n",
    "# determine only the output layer names that we need from YOLO detector\n",
    "ln = net.getLayerNames()\n",
    "ln = [ln[i[0] - 1] for i in net.getUnconnectedOutLayers()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Streaming the input video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the ID for \"person\" class\n",
    "personIdx = LABELS.index(\"person\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a VideoCapture object\n",
    "cap = cv2.VideoCapture(input_video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum Pixel to set threshold for Social distancing violation is 55.65961538461538\n"
     ]
    }
   ],
   "source": [
    "# Minimum distance (in pixels) for implementing social distancing\n",
    "num_iter = 10\n",
    "MIN_DISTANCE = get_min_dist(input_video, num_iter, net, ln, personIdx)\n",
    "print(\"Minimum Pixel to set threshold for Social distancing violation is {}\".format(MIN_DISTANCE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Social Distance Monitoring Tracker consist of number of people detected, number of people violated and social distancing Index\n",
    "tracker = []\n",
    "# loop over the frames from the video stream\n",
    "while True:\n",
    "    # read the next frame from the file\n",
    "    (grabbed, frame) = cap.read()\n",
    "\n",
    "    # if the frame was not grabbed, then we have reached the end of the stream\n",
    "    if not grabbed:\n",
    "        break\n",
    "\n",
    "    # resize the frame and then detect people (and only people) in it\n",
    "    frame = imutils.resize(frame, width=700)\n",
    "    results = detect_people(frame, net, ln, personIdx)\n",
    "\n",
    "    # initialize the set of indexes that violate the minimum social distance\n",
    "    violate = set()\n",
    "\n",
    "    # ensure there are *at least* two people detections (required in order to compute our pairwise distance maps)\n",
    "    if len(results) >= 2:\n",
    "        centroids = np.array([r[2] for r in results])\n",
    "        D = dist.cdist(centroids, centroids, metric=\"euclidean\")\n",
    "\n",
    "        # loop over the upper triangular of the distance matrix\n",
    "        for i in range(0, D.shape[0]):\n",
    "            for j in range(i + 1, D.shape[1]):\n",
    "                if D[i, j] < MIN_DISTANCE:\n",
    "                    violate.add(i)\n",
    "                    violate.add(j)\n",
    "\n",
    "    # loop over the results\n",
    "    for (i, (prob, bbox, centroid)) in enumerate(results):\n",
    "        # extract the bounding box and centroid coordinates, then initialize the color of the annotation\n",
    "        (startX, startY, endX, endY) = bbox\n",
    "        (cX, cY) = centroid\n",
    "        color = (255, 0, 0)\n",
    "\n",
    "        # if the index pair exists within the violation set, then update the color\n",
    "        if i in violate:\n",
    "            color = (0, 0, 255)\n",
    "\n",
    "        # draw (1) a bounding box around the person and (2) the centroid coordinates of the person\n",
    "        cv2.rectangle(frame, (startX, startY), (endX, endY), color, 1)\n",
    "        cv2.circle(frame, (cX, cY), 3, color, 1)\n",
    "\n",
    "    # draw the total number of social distancing violations on the output frame\n",
    "    font_scale = 1\n",
    "    font = cv2.FONT_HERSHEY_PLAIN\n",
    "    # set the rectangle background to white\n",
    "    rectangle_bgr = (255, 255, 255)\n",
    "    # Social Distancing Index scale 1 Good; 0 Poor\n",
    "    num_p = len(results)\n",
    "    num_v = len(violate)\n",
    "    SDidx = 1 - (num_v/num_p)\n",
    "    SDidx = np.round(SDidx, 2)\n",
    "    \n",
    "    # draw the total number of social distancing violations on the output frame\n",
    "    r = (num_p, num_v, SDidx)\n",
    "    tracker.append(r)\n",
    "    \n",
    "    text = \"Social Distancing Violations: {}\".format(len(violate))\n",
    "    cv2.putText(frame, text, (10, frame.shape[0] - 25), cv2.FONT_HERSHEY_SIMPLEX, 0.85, (0, 0, 255), 2)\n",
    "\n",
    "    # check to see if the output frame should be displayed to our screen\n",
    "    if display > 0:\n",
    "        # show the output frame\n",
    "        cv2.imshow(\"Frame\", frame)\n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "        # if the `q` key was pressed, break from the loop\n",
    "        if key == ord(\"q\"):\n",
    "            break\n",
    "\n",
    "    # if an output video file path has been supplied and the video writer has not been initialized, do so now\n",
    "    if  output_file != \"\" and writer is None:\n",
    "        # initialize our video writer\n",
    "        fourcc = cv2.VideoWriter_fourcc(*\"MJPG\")\n",
    "        writer = cv2.VideoWriter(output_file, fourcc, 12, (frame.shape[1], frame.shape[0]), True)\n",
    "\n",
    "    # if the video writer is not None, write the frame to the output video file\n",
    "    if writer is not None:\n",
    "        writer.write(frame)\n",
    "\n",
    "# When everything done, release the video capture and video write objects\n",
    "cap.release()\n",
    "writer.release()\n",
    "\n",
    "# Closes all the frames\n",
    "cv2.destroyAllWindows() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib as plt\n",
    "sns.set(style='whitegrid', palette=\"deep\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracker_df = pd.DataFrame(tracker, columns = [\"#People\", \"#Violation\", \"SD_index\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x576 with 8 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = tracker_df.hist(bins=15, figsize=(15, 8), layout=(2, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#People</th>\n",
       "      <th>#Violation</th>\n",
       "      <th>SD_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>530.000000</td>\n",
       "      <td>530.000000</td>\n",
       "      <td>530.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>18.900000</td>\n",
       "      <td>13.688679</td>\n",
       "      <td>0.281321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.141365</td>\n",
       "      <td>2.957683</td>\n",
       "      <td>0.117182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>11.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.050000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>18.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>0.180000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>19.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>0.280000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>20.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>0.350000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>24.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>0.690000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          #People  #Violation    SD_index\n",
       "count  530.000000  530.000000  530.000000\n",
       "mean    18.900000   13.688679    0.281321\n",
       "std      2.141365    2.957683    0.117182\n",
       "min     11.000000    4.000000    0.050000\n",
       "25%     18.000000   12.000000    0.180000\n",
       "50%     19.000000   14.000000    0.280000\n",
       "75%     20.000000   16.000000    0.350000\n",
       "max     24.000000   21.000000    0.690000"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tracker_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
